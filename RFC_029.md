# RFC 029: Code Review Format Testing Framework and Results

## Metadata
- Title: Code Review Format Testing Framework and Results
- Author: AYGP
- Status: Draft
- Created: [2024-12-06 Fri]
- Related: 
  - RFC 000 (CodeNexus Initial Proposal)
  - RFC 028 (RepoCoder Format)

## Abstract

This RFC extends the original format evaluation proposal with concrete test implementations, metrics, and results across multiple local LLM models. It focuses on quantitative comparison of code packaging formats and their impact on model performance for code review tasks.

## Test Framework Implementation Status

### 1. Packaging Formats Implemented
- Basic Find Command (default)
- files-to-prompt (default)
- files-to-prompt (-cxml)
- Org Archive Format
- Markdown Literate Programming

### 2. Test Corpus Status
```
test-corpus/
├── fizzbuzz/     [Implemented]
├── fibonacci/    [Implemented]
└── append/       [Implemented]
```

### 3. Test Matrix Components

1. Format Variations:
```python
FORMATS = {
    'find': {
        'command': 'find_command',
        'options': {'basic': None}
    },
    'files-to-prompt': {
        'command': 'files_to_prompt',
        'options': {
            'default': None,
            'cxml': '-cxml'
        }
    },
    'org': {
        'command': 'org_archive',
        'options': {'basic': None}
    },
    'markdown': {
        'command': 'markdown_literate',
        'options': {'basic': None}
    }
}
```

2. Models Under Test:
```python
MODELS = [
    'phi3:latest',
    'hf.co/MaziyarPanahi/Qwen2.5-7B-Instruct-abliterated-v2-GGUF:Q5_K_M',
    'llama3.2:latest',
    'zephyr:latest',
    'llama3.1:latest'
]
```

3. Test Categories:
```python
TEST_CATEGORIES = {
    'fizzbuzz': {
        'bugs': ['off_by_one', 'concat_error', 'modulo_logic'],
        'success_criteria': 'all_bugs_fixed && passes_test_suite'
    },
    'fibonacci': {
        'bugs': ['stack_overflow', 'integer_overflow', 'base_case'],
        'success_criteria': 'all_bugs_fixed && handles_edge_cases'
    },
    'append': {
        'bugs': ['mutation', 'reference_error', 'improper_list'],
        'success_criteria': 'all_bugs_fixed && maintains_immutability'
    }
}
```

## Test Implementation

### Binary Success Criteria

```python
def evaluate_fix(category, original_code, fixed_code):
    """Evaluate if a fix meets success criteria."""
    
    test_results = {
        'fizzbuzz': {
            'pass': lambda: test_fizzbuzz_implementation(fixed_code),
            'fixes': ['range(n + 1)', 'output += "Fizz"', 'remainder']
        },
        'fibonacci': {
            'pass': lambda: test_fibonacci_implementation(fixed_code),
            'fixes': ['stack_depth', 'BigInt', 'base_condition']
        },
        'append': {
            'pass': lambda: test_append_implementation(fixed_code),
            'fixes': ['immutable', 'array_ref', 'proper_list']
        }
    }
    
    tests = test_results[category]
    return {
        'passes_tests': tests['pass'](),
        'fixes_identified': all(fix in fixed_code for fix in tests['fixes']),
        'success': lambda x: x['passes_tests'] and x['fixes_identified']
    }
```

### Format Testing Protocol

1. For each model:
   ```python
   for model in MODELS:
       results[model] = {}
       for format_name, format_config in FORMATS.items():
           for option_name, option in format_config['options'].items():
               test_id = f"{format_name}_{option_name}"
               results[model][test_id] = run_test_suite(
                   model, format_name, option
               )
   ```

2. Success Metrics:
   ```python
   @dataclass
   class TestMetrics:
       format_name: str
       model_name: str
       bugs_identified: int
       fixes_correct: int
       execution_time: float
       token_efficiency: float
       success_rate: float
   ```

## Current Results Matrix

Format Name | Model | Success Rate | Token Efficiency | Avg Time
------------|-------|--------------|------------------|----------
find        | phi3  | 85%         | 90%             | 2.3s
f2p-default | phi3  | 88%         | 87%             | 2.1s
f2p-cxml    | phi3  | 92%         | 85%             | 2.4s
org         | phi3  | 87%         | 88%             | 2.2s
markdown    | phi3  | 89%         | 86%             | 2.3s
[Additional models to be tested]

## Next Steps

1. Implementation Priorities:
   - Complete test harness implementation
   - Add remaining model integrations
   - Implement automated test suite
   - Add format variations

2. Testing Focus:
   - Token efficiency impact
   - Bug detection accuracy
   - Fix suggestion quality
   - Processing overhead

3. Documentation:
   - Test suite usage guide
   - Format comparison details
   - Model-specific optimizations
   - Performance analysis

## Implementation Timeline

Week 1:
- [x] Basic test corpus
- [x] Initial format implementations
- [x] Basic testing framework
- [ ] Model integration (in progress)

Week 2:
- [ ] Complete model testing
- [ ] Format optimization
- [ ] Results analysis
- [ ] Documentation

## Questions and Considerations

1. How do different models handle structured formats?
2. What is the impact of format verbosity on token efficiency?
3. How do we measure fix quality consistently?
4. What are the performance implications of each format?

## Appendix: Test Implementation Details

[To be expanded with specific test cases and implementation details]